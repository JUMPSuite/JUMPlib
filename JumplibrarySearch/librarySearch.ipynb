{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dangerous-consequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from normalization_PSMSHandler import *\n",
    "\n",
    "from mainSearchFunctions import *\n",
    "from postSearchProcessing import *\n",
    "\n",
    "import re, numpy as np\n",
    "import math\n",
    "import os\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "from logFunctions import *\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "import configparser\n",
    "config = configparser.ConfigParser()\n",
    "from os.path import dirname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "refined-switzerland",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bored-london",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/spoudel1/Desktop/JUMPp_lib_program/JumplibrarySearchParallel_TwoScores'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "careful-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the parameter file using configparser\n",
    "params_file = \"../Test_search_parallel_8cores/specLib_firstSearch.params\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dietary-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config.read(params_file)\n",
    "\n",
    "# exp_mzxml = config[\"specLib\"][\"exp_mzxml\"] #raw file\n",
    "exp_ms2 = config[\"specLib\"][\"exp_ms2\"] #raw file\n",
    "specLibFolder = config[\"specLib\"][\"specLibFolder\"] #library containing folder\n",
    "ms1_tol = float(config[\"specLib\"][\"ms1_tol\"]) #precursor ion tolerance\n",
    "\n",
    "top_ions_control = config[\"specLib\"][\"top_ions_control\"]\n",
    "top_ions_min_max = config[\"specLib\"][\"top_ions\"] #total number of top library ions that should be present in spectrum \n",
    "ms2_tol = float(config[\"specLib\"][\"ms2_tol\"]) #fragment ion tolerance\n",
    "# rt_fdr = float(config[\"specLib\"][\"rt_fdr\"]) #rt tolerance in SD\n",
    "#window number determines the lenght of mz for normalization of intensity\n",
    "window_number = int(config[\"specLib\"][\"window_number\"])\n",
    "\n",
    "binsize = config[\"specLib\"][\"binsize\"] #binning width for selecting top ions in the ms2 spectrum \n",
    "top_ions_per_bin = int(config[\"specLib\"][\"top_ions_per_bin\"]) #maximum fragment ions that are selected from raw spectrum for each bin\n",
    "\n",
    "start_end_scan_range = config[\"specLib\"][\"start_end_scan_range\"] #start and end scans supplied by users\n",
    "\n",
    "# outputFolder = fileroot+\"/\"+config[\"specLib\"][\"outputFolder\"] #search results are stored in this folder\n",
    "\n",
    "#score method\n",
    "method = config[\"specLib\"][\"method\"]\n",
    "null_search = config[\"specLib\"][\"null_search\"]\n",
    "sim_mass = float(config[\"specLib\"][\"sim_mass\"])\n",
    "n_cores = int(config[\"specLib\"][\"n_cores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "potential-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_search =\"0\"\n",
    "n_ions = 20\n",
    "topRanks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "obvious-crazy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#THis is additional step for local work as we use the program from jupyter notebook\n",
    "os.chdir(dirname(exp_ms2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charged-nitrogen",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputFolder = exp_ms2.split(\"/\")[-1].split(\".ms2\")[0]\n",
    "makedirectory(outputFolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "found-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check null search and if null_search = 1, sim_mass needs to be added else it is 0\n",
    "if null_search == \"0\":\n",
    "    sim_mass = 0.0\n",
    "\n",
    "#tolerace type for dynamic or static tolerance\n",
    "\n",
    "tolerance_type = config[\"specLib\"][\"tolerance_type\"]\n",
    "\n",
    "#Dynamice tolerance file if dynamic tolerance is selected\n",
    "\n",
    "dyn_tol_file = config[\"specLib\"][\"dyn_tol_file\"]\n",
    "\n",
    "\n",
    "#tolerance for ms2 matching = fragment ion tolerance\n",
    "tol = float(config[\"specLib\"][\"tol\"])\n",
    "#example pepxml file to parse the modification information\n",
    "tmt = config[\"specLib\"][\"tmt\"]\n",
    "\n",
    "#Let us first look at the all protein ppml file\n",
    "\n",
    "libtype = float(config[\"specLib\"][\"libtype\"])\n",
    "\n",
    "min_top_ions = int(top_ions_min_max.split(\",\")[0])\n",
    "top_ions = int(top_ions_min_max.split(\",\")[1])\n",
    "\n",
    "\n",
    "#this dictionaryneeds to be updated with other datatype\n",
    "libtypeDict = {1:\"tmt18_default\", 2:\"tmt11_default\", 3:\"tmt18_pho\", 4:\"tmt11_pho\", 5:\"tmt18_ub\", 6:\"tmt11_ub\", 100:\"labelfree_default\", 1000:\"silaclys_default\"}\n",
    "libtypename = libtypeDict[int(libtype)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seven-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take all protein ppml file first\n",
    "all_prot_ppml = specLibFolder+\"/intermediate/id_all_pep.ppml\"\n",
    "#make all protein ppml file dataframe\n",
    "all_prot_ppmlDF = fileToDF(all_prot_ppml)\n",
    "id_prot = all_prot_ppmlDF[[\"PeptideSeqWithRealDelMass\",\"Protein Accession #\"]]\n",
    "#rename names for consistency and groupby peptide ID and get accession separated by ,\n",
    "idProtDF = id_prot.groupby('PeptideSeqWithRealDelMass').agg( lambda x: ','.join(list(x))).reset_index()\n",
    "#protein maped to peptide dataframe\n",
    "# print (idProtDF.columns)\n",
    "idProtDF.rename(columns = {\"PeptideSeqWithRealDelMass\":\"Peptide\",\"Protein Accession #\":\"Protein\"}, inplace=True)\n",
    "L_ID_allProtDict = dict(zip(idProtDF.Peptide, idProtDF.Protein))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "controversial-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set current directory as working directory\n",
    "# path = os.getcwd()\n",
    "# os.chdir(path)\n",
    "\n",
    "# exp_ms2 = \"/Users/spoudel1/Desktop/JUMP_specLib/Program/ms2/preprocess/FTLD_Batch2_F50.ms2\"\n",
    "specLib = specLibFolder+\"/jumplib_human_{}.splib\".format(libtypename)\n",
    "# specLib = \"/Users/spoudel1/Desktop/JUMP_specLib/specLib/OneFraction/SpectralLibraryTargetDecoy.spLib\"\n",
    "\n",
    "\n",
    "#expMZXML = exp_ms2.split(\"/\")[-1].split(\".\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adequate-tuition",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_sd_dict = {}\n",
    "if tolerance_type.upper() == \"DYNAMIC\":\n",
    "    int_sd_dict = parseDynamicIntensityFile(dyn_tol_file,tol)\n",
    "\n",
    "\n",
    "logFile = outputFolder+\"/jump_lib_s.log\"\n",
    "\n",
    "#removing log file if previously present\n",
    "try:\n",
    "    rmFile(logFile)\n",
    "except:\n",
    "    print (\"No jump_lib_s.log is present. Writing log file now\")\n",
    "\n",
    "\n",
    "\n",
    "# filename = exp_ms2.split(\"/\")[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "binary-operation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing experimental ms2 file and storing as dataframe. Below is the summary\n",
      "Name of input file = /Users/spoudel1/Desktop/Spectral_Library_Search/htmt_301/htmt_b301_f001.ms2\n",
      "This will take time depending on size of ms2 file\n",
      "\n",
      "The total number of precursor candidates (dtas) are 32358\n",
      "\n",
      "Parsing Spectral Library database and storing as dataframe. Below is the summary\n",
      "This will take time depending on size of ms2 file\n"
     ]
    }
   ],
   "source": [
    "write_log (logFile,\"Parsing experimental ms2 file and storing as dataframe. Below is the summary\")\n",
    "write_log (logFile,\"Name of input file = {}\".format(exp_ms2))\n",
    "write_log (logFile,\"This will take time depending on size of ms2 file\")\n",
    "\n",
    "#simulated mass changes the precursor m/z by sim_mass dalton. This simulation is just done at the input file not in the library\n",
    "expDF_all = ms2ToDf_spec(exp_ms2, sim_mass)\n",
    "write_log (logFile,\"\\nThe total number of precursor candidates (dtas) are {}\".format(expDF_all.shape[0]))\n",
    "\n",
    "write_log (logFile,\"\\nParsing Spectral Library database and storing as dataframe. Below is the summary\")\n",
    "write_log (logFile,\"This will take time depending on size of ms2 file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "tested-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check to see if the user has supplied start and end scans\n",
    "\n",
    "start_end = start_end_scan_range.split(\",\")\n",
    "start_scan = int(start_end[0])\n",
    "end_scan = int(start_end[1])\n",
    "\n",
    "#parse the expDF_all to get the start and end scans only\n",
    "\n",
    "if end_scan != 0:\n",
    "    expDF = expDF_all.loc[(expDF_all.scan >= start_scan) & (expDF_all.scan <= end_scan)]\n",
    "else:\n",
    "    expDF = expDF_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "promising-munich",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There should be a pickle file in the specLibFolder but just to make sure\n",
    "if os.path.exists(specLibFolder+\"/jumplib_human_{}.pkl\".format(libtypename)):\n",
    "    libDF = pd.read_pickle(specLibFolder+\"/jumplib_human_{}.pkl\".format(libtypename))\n",
    "else:\n",
    "    libDF = ms2ToDf_spec(specLib)\n",
    "   #outfilename = specLibFolder+\"/jumplib_human_{}.splib\".format(libtypename) \n",
    "    libDF.to_pickle(specLibFolder+\"/jumplib_human_{}.pkl\".format(libtypename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "recent-congress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The total TARGET entries in Library are 383526.0\n"
     ]
    }
   ],
   "source": [
    "write_log (logFile,\"\\nThe total TARGET entries in Library are {}\".format(libDF.shape[0]/2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "registered-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "if method != \"normalized_dot_product\":\n",
    "    write_log (logFile,\"Since the scoring method is not normalized dot product. We are normalizing the intensity. Performing normalization step\\n\")\n",
    "    normalizeIntensity(expDF,window_number)\n",
    "    normalizeIntensity(libDF,window_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "engaged-float",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tolerance_type.upper() == \"DYNAMIC\":\n",
    "    logTransformMS2Intensity(expDF)#this is for dynamic intensity tolerance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "peaceful-lounge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Library searching is underway. Below are the list of major steps performed\n",
      "Matching Precursor ions with ms1 tolerace (ppm) = 10.0\n",
      "Matching product ions\n",
      "Searching for top matching fragment ions 3\n",
      "If found, cleaning the library entries for redundancy\n",
      "Preprocessing input spectra for pattern matching\n",
      "For each library product ions, look for ions with tolerance (ppm) = 10.0\n",
      "If no match found intensity = 0 to that product ion\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_log (logFile,\"\\nLibrary searching is underway. Below are the list of major steps performed\")\n",
    "write_log (logFile,\"Matching Precursor ions with ms1 tolerace (ppm) = {}\".format(ms1_tol))\n",
    "write_log (logFile,\"Matching product ions\")\n",
    "write_log (logFile,\"Searching for top matching fragment ions {}\".format(top_ions))\n",
    "write_log (logFile,\"If found, cleaning the library entries for redundancy\")\n",
    "write_log (logFile,\"Preprocessing input spectra for pattern matching\")\n",
    "write_log (logFile,\"For each library product ions, look for ions with tolerance (ppm) = {}\".format(ms2_tol))\n",
    "write_log (logFile,\"If no match found intensity = 0 to that product ion\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "abroad-bumper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_TopN_Lib_ions(exp_mz_list, intensity_exp, matched_library_DF, n_ions, ms2_tol, topRanks=10): #top_ion is the minimum no of ions (intensity ranked top) that should be present in experimental mz \n",
    "    \n",
    "    \n",
    "    dotProductList = [] #this checks if top_ion are present in exp_mz_list\n",
    "    \n",
    "    #this is to speed up the scanning process as numpy array are fastest\n",
    "    mz_cols = list(matched_library_DF.columns) #for indexing columns\n",
    "    np_arr = matched_library_DF.to_numpy() #numpy array conversion of dataframe\n",
    "    for row in np_arr: #each matched library checked for top ions according to parameters above\n",
    "        mz = row[mz_cols.index(\"m/z\")] #mz list (ms2)\n",
    "        intensity = row[mz_cols.index(\"intensity\")] #intensity list (ms2)\n",
    "        scan = str(row[mz_cols.index(\"scan\")]) #scan \n",
    "       \n",
    "        ind = np.argsort([-i for i in intensity]) #sorting by descending order intensity\n",
    "        \n",
    "\n",
    "        top_ion_lib = {\"mz\":[],\"intensity\":[]} #empty dict for top ion collection\n",
    "        \n",
    "        top_ion_lib[\"mz\"] = [mz[i] for i in ind[0:n_ions]]\n",
    "        top_ion_lib[\"intensity\"] = [intensity[i] for i in ind[0:n_ions]]\n",
    "        \n",
    "        \n",
    "        cnt = 0\n",
    "        #make a trimeed spectral dictionary and update it as the ion is within the tolerance\n",
    "        tr_featSpec = {}\n",
    "\n",
    "\n",
    "        \n",
    "        for ion in top_ion_lib[\"mz\"]: #looping over top_ions to see if they are present in experimental mz\n",
    "            for index, masses in enumerate(exp_mz_list):\n",
    "                massshift = ppmCalc(float(ion), float(masses), ms2_tol)\n",
    "                if abs(massshift) < ms2_tol:\n",
    "                    if ion not in tr_featSpec.keys():\n",
    "                        tr_featSpec[ion]=intensity_exp[index]\n",
    "                    \n",
    "                        \n",
    "                    else:\n",
    "                        old_intensity = tr_featSpec[ion]\n",
    "                        \n",
    "                        if intensity_exp[index] > old_intensity:\n",
    "                            tr_featSpec[ion] = intensity_exp[index] \n",
    "        \n",
    "        \n",
    "#         print (\"Top library ions \",top_ion_lib[\"mz\"])\n",
    "        \n",
    "        tr_featSpec2 = {\"mz\":[],\"intensity\":[]}\n",
    "        \n",
    "        for ions in top_ion_lib[\"mz\"]:\n",
    "            #add intensity 0 to all the ions that are present in library but are not within the given tolerance in spectrum raw\n",
    "            if ions in tr_featSpec.keys():\n",
    "                tr_featSpec2[\"mz\"].append(ions)\n",
    "                tr_featSpec2[\"intensity\"].append(tr_featSpec[ions])\n",
    "            else:\n",
    "                tr_featSpec2[\"mz\"].append(ions)\n",
    "                tr_featSpec2[\"intensity\"].append(0.0)\n",
    "\n",
    "#         print (tr_featSpec2)\n",
    "        \n",
    "        #compute normalized dot product here\n",
    "        spec_query = np.array(tr_featSpec2[\"intensity\"])\n",
    "        spec_reference = np.array(top_ion_lib[\"intensity\"])\n",
    "        \n",
    "        dp = normalizedDotProduct(spec_query,spec_reference)\n",
    "        dotProductList.append(dp)\n",
    "        \n",
    "    matched_library_DF[\"QuickDotProduct\"] = dotProductList\n",
    "    #Select top 10 Ranks\n",
    "    matched_lib_DF_top = matched_library_DF.sort_values(by=[\"QuickDotProduct\"], ascending=False)\n",
    "        \n",
    "    return matched_lib_DF_top.iloc[0:topRanks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "indie-flashing",
   "metadata": {},
   "outputs": [],
   "source": [
    "expDF = expDF_all.iloc[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "interpreted-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(expDF,libDF,n_ions, ms2_tol,ms1_tol, int_sd_dict,topRanks,method=\"normalized_dot_product\"):\n",
    "    \n",
    "    mz_cols = list(expDF.columns)\n",
    "    np_arr = expDF.to_numpy()\n",
    "\n",
    "    dot_product_results = {}\n",
    "    cnt = 0\n",
    "    update = 10000\n",
    "    \n",
    "    for row in np_arr:\n",
    "        scan = str(row[mz_cols.index(\"scan\")])\n",
    "        charge = int(row[mz_cols.index(\"charge\")])\n",
    "        precMZ = float(row[mz_cols.index(\"prec_MZ\")])\n",
    "        mz = row[mz_cols.index(\"m/z\")]\n",
    "        \n",
    "        intensity = list(row[mz_cols.index(\"intensity\")])\n",
    "        matched_lib_DF = scanPrecursorMatch(precMZ, charge, libDF, ms1_tol)\n",
    "        \n",
    "        \n",
    "        if matched_lib_DF.shape[0] >=1: #there may not be any matches to the library so we have to check the library match to avoid error\n",
    "            matched_lib_DF_top2 = select_TopN_Lib_ions(mz, intensity, matched_lib_DF, n_ions, ms2_tol, topRanks)\n",
    "            spectrumInputDict = {\"mz\":mz,\"intensity\":intensity}\n",
    "            tolInputDict = {}\n",
    "            cnt+=1\n",
    "            \n",
    "            mz_cols2 = list(matched_lib_DF_top2.columns)\n",
    "            np_arr2 = matched_lib_DF_top2.to_numpy()\n",
    "            for row2 in np_arr2: \n",
    "                #removal of library cleaning step enables us to directly generate lib_mz_int_dict\n",
    "                #lib_mz_int_dict2 = {}\n",
    "                lib_mz_int_dict = {}\n",
    "                L_ID = row2[mz_cols2.index(\"L_ID\")]\n",
    "                RT = row2[mz_cols2.index(\"RT\")]\n",
    "                L_peptide = row2[mz_cols2.index(\"L_peptide\")]\n",
    "                prec_mz = row2[mz_cols2.index(\"prec_MZ\")]\n",
    "    #             print(L_peptide)\n",
    "\n",
    "                #library cleaning step is removed so lib_mz_int_dict2 can be saved as lib_mz_int_dict\n",
    "\n",
    "                lib_mz_int_dict[\"mz\"] = row2[mz_cols2.index(\"m/z\")]\n",
    "\n",
    "                # print (\"The library entry is {} and peptide is {}\".format(L_ID, L_peptide))\n",
    "                # print (\"Length of library product ions = {}\".format(len(lib_mz_int_dict2[\"mz\"])))\n",
    "\n",
    "                if method == \"normalized_dot_product\":\n",
    "                    lib_mz_int_dict[\"intensity\"] = list(row2[mz_cols2.index(\"intensity\")]) #use normalize dictionary for the library input\n",
    "                else:\n",
    "                    lib_mz_int_dict[\"intensity\"] = list(row2[mz_cols2.index(\"normalized_intensity\")]) #use normalize dictionary for the library input            \n",
    "    #             #tolerance_type defines how to choose the tolerance Dynamic will use the int_sd_dict dictionary else static tolerace will be used\n",
    "                #clean library ions too to check for ions within mass tolerance           \n",
    "                \n",
    "\n",
    "                #may be this is not required as we have all theoretical ions\n",
    "                #lib_mz_int_dict = cleanLibRedundancy(lib_mz_int_dict2, ms2_tol)\n",
    "                \n",
    "\n",
    "                tr_featSpec = trimFeatSpec(spectrumInputDict,tolInputDict,int_sd_dict,tolerance_type,lib_mz_int_dict,ms2_tol) #int_sd_dict = tolerance SD defined intensity from the file after mass calibration\n",
    "                #dp = calcMS2Similarity(tr_featSpec,lib_mz_int_dict,ms2_tol)\n",
    "                #input for other scoring techniques\n",
    "                spec_query = np.array(tr_featSpec[\"intensity\"])\n",
    "                spec_reference = np.array(lib_mz_int_dict[\"intensity\"])\n",
    "                #print (spec_query)\n",
    "                #print (spec_reference)\n",
    "\n",
    "                #if method == \"JiHoon_Norm_DP\":\n",
    "                #    dp = calcMS2Similarity(tr_featSpec,lib_mz_int_dict,ms2_tol)\n",
    "\n",
    "\n",
    "                if method == \"normalized_dot_product\":\n",
    "                    dp = normalizedDotProduct(spec_query,spec_reference)\n",
    "\n",
    "                else:\n",
    "                    spec_query_ = conversionDictSpecToNumpyArrayFormat(tr_featSpec)\n",
    "                    spec_reference_ = conversionDictSpecToNumpyArrayFormat(lib_mz_int_dict)\n",
    "\t\t    \n",
    "                    if method == \"DoubleNormalizedDP\":\n",
    "                        dp = normalizedDotProduct(spec_query,spec_reference)\n",
    "                    if method == \"DP_Peng\":\n",
    "                        dp = DP_Peng_similarity(spec_query,spec_reference)\n",
    "                    if method == \"unweighted_entropy\":\n",
    "                        dp = unweightedEntropySimCalc(spec_query_,spec_reference_)\n",
    "                    if method == \"dot_product\":\n",
    "                        dp = dot_product_similarity(spec_query,spec_reference)\n",
    "                    if method == \"fidelity\":\n",
    "                        dp = fidelity_similarity(spec_query,spec_reference)\n",
    "                    if method == \"bhattacharya_2\":\n",
    "                        dp = bhattacharya_2_similarity(spec_query,spec_reference)\n",
    "\n",
    "                if \"Decoy_\" in L_peptide:\n",
    "                    L_peptide2 = L_peptide.split(\";\")\n",
    "                    L_peptide = \"{};{};{}\".format(L_peptide2[0],L_peptide2[1],prec_mz)\n",
    "                scanKey = str(scan)+\".\"+str(charge)+\".\"+str(precMZ)\n",
    "\n",
    "\n",
    "                if scanKey not in dot_product_results.keys():\n",
    "                    dot_product_results[scanKey] = [L_ID+\";\"+str(dp)+\";\"+str(RT)+\";\"+L_peptide]\n",
    "                else:\n",
    "                    dot_product_results[scanKey].append(L_ID+\";\"+str(dp)+\";\"+str(RT)+\";\"+L_peptide)\n",
    "                     \n",
    "        \n",
    "        if cnt == update:\n",
    "            remainingScans = len(expDF) - cnt\n",
    "            print (\"Total scan searched = \", cnt,\"\\nRemaining scans = \" ,remainingScans)\n",
    "            update+=10000\n",
    "       \n",
    "    final_result = {}\n",
    "    for results in dot_product_results.keys():\n",
    "    #     print (len(dot_product_results[results]))\n",
    "        final_result[results] = \",\".join(dot_product_results[results])\n",
    "#     print (final_result) \n",
    "    return final_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "front-danger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scan</th>\n",
       "      <th>charge</th>\n",
       "      <th>[M+H]+</th>\n",
       "      <th>prec_MZ</th>\n",
       "      <th>L_ID</th>\n",
       "      <th>L_peptide</th>\n",
       "      <th>L_protein</th>\n",
       "      <th>RT</th>\n",
       "      <th>m/z</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1103.133405</td>\n",
       "      <td>1103.133405</td>\n",
       "      <td>p0000001</td>\n",
       "      <td>A(304.2071453)AAAAAAAAAAAAAAGAGAGAK(304.207145...</td>\n",
       "      <td>sp|P55011|S12A2_HUMAN</td>\n",
       "      <td>82.245</td>\n",
       "      <td>[348.2566209, 376.2515356, 419.2937347, 447.28...</td>\n",
       "      <td>[285448.0, 1103696.0, 96475.0, 983727.0, 13049...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>735.758029</td>\n",
       "      <td>735.758029</td>\n",
       "      <td>p0000002</td>\n",
       "      <td>A(304.2071453)AAAAAAAAAAAAAAGAGAGAK(304.207145...</td>\n",
       "      <td>sp|P55011|S12A2_HUMAN</td>\n",
       "      <td>82.800</td>\n",
       "      <td>[295.1850767, 330.7036336, 348.2566209, 366.22...</td>\n",
       "      <td>[163895.0, 1547760.0, 10665.0, 4151911.0, 1537...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1246.146653</td>\n",
       "      <td>1246.146653</td>\n",
       "      <td>p0000003</td>\n",
       "      <td>A(304.2071453)AAAAAAAAAAPPAPPEGASPGDSAR;2;1246...</td>\n",
       "      <td>sp|Q8WXD9|CSKI1_HUMAN</td>\n",
       "      <td>42.315</td>\n",
       "      <td>[158.0924031, 175.1189522, 229.1295169, 246.15...</td>\n",
       "      <td>[28615.0, 191149.0, 3926.0, 30670.0, 13716.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>595.352256</td>\n",
       "      <td>595.352256</td>\n",
       "      <td>p0000004</td>\n",
       "      <td>A(304.2071453)AAAAAAAAAR;2;595.3522559</td>\n",
       "      <td>sp|Q9Y651|SOX21_HUMAN</td>\n",
       "      <td>18.841</td>\n",
       "      <td>[158.0924031, 175.1189522, 229.1295169, 246.15...</td>\n",
       "      <td>[11051.0, 40249.0, 6927.0, 3775.0, 5985.0, 316...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>697.934198</td>\n",
       "      <td>697.934198</td>\n",
       "      <td>p0000005</td>\n",
       "      <td>A(304.2071453)AAAAAAAAK(304.2071453);2;697.934...</td>\n",
       "      <td>sp|Q99453|PHX2B_HUMAN</td>\n",
       "      <td>24.230</td>\n",
       "      <td>[348.2566209, 376.2515356, 419.2937347, 447.28...</td>\n",
       "      <td>[13755.0, 50439.0, 4374.0, 36874.0, 39993.0, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767047</th>\n",
       "      <td>458010</td>\n",
       "      <td>1</td>\n",
       "      <td>1028.605961</td>\n",
       "      <td>1028.605961</td>\n",
       "      <td>Decoy_p0074484</td>\n",
       "      <td>Decoy_Y(304.2071453)VLSSR;1;1028.6059607</td>\n",
       "      <td>Decoy_sp|P12532|KCRU_HUMAN</td>\n",
       "      <td>49.753</td>\n",
       "      <td>[158.0924031, 175.1189522, 257.160817, 274.187...</td>\n",
       "      <td>[4414.0, 163419.0, 14817.0, 46136.0, 13258.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767048</th>\n",
       "      <td>458013</td>\n",
       "      <td>2</td>\n",
       "      <td>1634.747360</td>\n",
       "      <td>817.877318</td>\n",
       "      <td>Decoy_p0074487</td>\n",
       "      <td>Decoy_Y(304.2071453)VM(15.99492)PSC(57.02146)E...</td>\n",
       "      <td>Decoy_sp|Q9H4F8|SMOC1_HUMAN</td>\n",
       "      <td>34.761</td>\n",
       "      <td>[158.0924031, 175.1189522, 272.1353305, 273.11...</td>\n",
       "      <td>[1242955.0, 9359339.0, 92829.0, 758519.0, 5448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767049</th>\n",
       "      <td>458024</td>\n",
       "      <td>2</td>\n",
       "      <td>2157.015800</td>\n",
       "      <td>1079.011538</td>\n",
       "      <td>Decoy_p0074498</td>\n",
       "      <td>Decoy_Y(304.2071453)VNM(15.99492)QDPEM(15.9949...</td>\n",
       "      <td>Decoy_sp|O00217|NDUS8_HUMAN</td>\n",
       "      <td>55.858</td>\n",
       "      <td>[158.0924031, 175.1189522, 255.1451669, 272.17...</td>\n",
       "      <td>[15620.0, 82088.0, 28507.0, 189451.0, 32194.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767050</th>\n",
       "      <td>458025</td>\n",
       "      <td>2</td>\n",
       "      <td>2141.020880</td>\n",
       "      <td>1071.014078</td>\n",
       "      <td>Decoy_p0074499</td>\n",
       "      <td>Decoy_Y(304.2071453)VNM(15.99492)QDPEM(15.9949...</td>\n",
       "      <td>Decoy_sp|O00217|NDUS8_HUMAN</td>\n",
       "      <td>76.455</td>\n",
       "      <td>[440.2828357, 451.3199495, 468.2777503, 539.35...</td>\n",
       "      <td>[696817.0, 375554.0, 1338830.0, 207055.0, 6126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767051</th>\n",
       "      <td>458115</td>\n",
       "      <td>3</td>\n",
       "      <td>2331.290003</td>\n",
       "      <td>777.768185</td>\n",
       "      <td>Decoy_p0074589</td>\n",
       "      <td>Decoy_Y(304.2071453)YETSK(304.2071453)EEELK(30...</td>\n",
       "      <td>Decoy_sp|Q68DA7|FMN1_HUMAN</td>\n",
       "      <td>84.673</td>\n",
       "      <td>[158.0924031, 175.1189522, 280.6536094, 305.16...</td>\n",
       "      <td>[4505.0, 25633.0, 1023.0, 3665.0, 12176.0, 358...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767052 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          scan  charge       [M+H]+      prec_MZ            L_ID  \\\n",
       "0            1       2  1103.133405  1103.133405        p0000001   \n",
       "1            2       3   735.758029   735.758029        p0000002   \n",
       "2            3       2  1246.146653  1246.146653        p0000003   \n",
       "3            4       2   595.352256   595.352256        p0000004   \n",
       "4            5       2   697.934198   697.934198        p0000005   \n",
       "...        ...     ...          ...          ...             ...   \n",
       "767047  458010       1  1028.605961  1028.605961  Decoy_p0074484   \n",
       "767048  458013       2  1634.747360   817.877318  Decoy_p0074487   \n",
       "767049  458024       2  2157.015800  1079.011538  Decoy_p0074498   \n",
       "767050  458025       2  2141.020880  1071.014078  Decoy_p0074499   \n",
       "767051  458115       3  2331.290003   777.768185  Decoy_p0074589   \n",
       "\n",
       "                                                L_peptide  \\\n",
       "0       A(304.2071453)AAAAAAAAAAAAAAGAGAGAK(304.207145...   \n",
       "1       A(304.2071453)AAAAAAAAAAAAAAGAGAGAK(304.207145...   \n",
       "2       A(304.2071453)AAAAAAAAAAPPAPPEGASPGDSAR;2;1246...   \n",
       "3                  A(304.2071453)AAAAAAAAAR;2;595.3522559   \n",
       "4       A(304.2071453)AAAAAAAAK(304.2071453);2;697.934...   \n",
       "...                                                   ...   \n",
       "767047           Decoy_Y(304.2071453)VLSSR;1;1028.6059607   \n",
       "767048  Decoy_Y(304.2071453)VM(15.99492)PSC(57.02146)E...   \n",
       "767049  Decoy_Y(304.2071453)VNM(15.99492)QDPEM(15.9949...   \n",
       "767050  Decoy_Y(304.2071453)VNM(15.99492)QDPEM(15.9949...   \n",
       "767051  Decoy_Y(304.2071453)YETSK(304.2071453)EEELK(30...   \n",
       "\n",
       "                          L_protein      RT  \\\n",
       "0             sp|P55011|S12A2_HUMAN  82.245   \n",
       "1             sp|P55011|S12A2_HUMAN  82.800   \n",
       "2             sp|Q8WXD9|CSKI1_HUMAN  42.315   \n",
       "3             sp|Q9Y651|SOX21_HUMAN  18.841   \n",
       "4             sp|Q99453|PHX2B_HUMAN  24.230   \n",
       "...                             ...     ...   \n",
       "767047   Decoy_sp|P12532|KCRU_HUMAN  49.753   \n",
       "767048  Decoy_sp|Q9H4F8|SMOC1_HUMAN  34.761   \n",
       "767049  Decoy_sp|O00217|NDUS8_HUMAN  55.858   \n",
       "767050  Decoy_sp|O00217|NDUS8_HUMAN  76.455   \n",
       "767051   Decoy_sp|Q68DA7|FMN1_HUMAN  84.673   \n",
       "\n",
       "                                                      m/z  \\\n",
       "0       [348.2566209, 376.2515356, 419.2937347, 447.28...   \n",
       "1       [295.1850767, 330.7036336, 348.2566209, 366.22...   \n",
       "2       [158.0924031, 175.1189522, 229.1295169, 246.15...   \n",
       "3       [158.0924031, 175.1189522, 229.1295169, 246.15...   \n",
       "4       [348.2566209, 376.2515356, 419.2937347, 447.28...   \n",
       "...                                                   ...   \n",
       "767047  [158.0924031, 175.1189522, 257.160817, 274.187...   \n",
       "767048  [158.0924031, 175.1189522, 272.1353305, 273.11...   \n",
       "767049  [158.0924031, 175.1189522, 255.1451669, 272.17...   \n",
       "767050  [440.2828357, 451.3199495, 468.2777503, 539.35...   \n",
       "767051  [158.0924031, 175.1189522, 280.6536094, 305.16...   \n",
       "\n",
       "                                                intensity  \n",
       "0       [285448.0, 1103696.0, 96475.0, 983727.0, 13049...  \n",
       "1       [163895.0, 1547760.0, 10665.0, 4151911.0, 1537...  \n",
       "2       [28615.0, 191149.0, 3926.0, 30670.0, 13716.0, ...  \n",
       "3       [11051.0, 40249.0, 6927.0, 3775.0, 5985.0, 316...  \n",
       "4       [13755.0, 50439.0, 4374.0, 36874.0, 39993.0, 4...  \n",
       "...                                                   ...  \n",
       "767047  [4414.0, 163419.0, 14817.0, 46136.0, 13258.0, ...  \n",
       "767048  [1242955.0, 9359339.0, 92829.0, 758519.0, 5448...  \n",
       "767049  [15620.0, 82088.0, 28507.0, 189451.0, 32194.0,...  \n",
       "767050  [696817.0, 375554.0, 1338830.0, 207055.0, 6126...  \n",
       "767051  [4505.0, 25633.0, 1023.0, 3665.0, 12176.0, 358...  \n",
       "\n",
       "[767052 rows x 10 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "libDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "close-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ions = 10\n",
    "topRanks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "basic-belize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOtal frames completed 1\n",
      "TOtal frames completed 2\n",
      "TOtal frames completed 3\n",
      "TOtal frames completed 4\n",
      "TOtal frames completed 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-6a66862d048b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_split\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlibDF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_ions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms2_tol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mms1_tol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_sd_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtopRanks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"normalized_dot_product\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"TOtal frames completed {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcnt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-db5cff2dfa94>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(expDF, libDF, n_ions, ms2_tol, ms1_tol, int_sd_dict, topRanks, method)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                 \u001b[0mtr_featSpec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrimFeatSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspectrumInputDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtolInputDict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint_sd_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtolerance_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlib_mz_int_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mms2_tol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#int_sd_dict = tolerance SD defined intensity from the file after mass calibration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;31m#dp = calcMS2Similarity(tr_featSpec,lib_mz_int_dict,ms2_tol)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;31m#input for other scoring techniques\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/JUMPp_lib_program/JumplibrarySearchParallel_TwoScores/mainSearchFunctions.py\u001b[0m in \u001b[0;36mtrimFeatSpec\u001b[0;34m(featSpec, tolInputDict, int_sd_dict, tolerance_type, libSpec, ms2_tol)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlibIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmzLib\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibSpec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mz\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasses\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalibrationList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mmassshift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppmCalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmzLib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtolerance_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"DYNAMIC\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmassshift\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mcheckToleranceLevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/JUMPp_lib_program/JumplibrarySearchParallel_TwoScores/normalization_PSMSHandler.py\u001b[0m in \u001b[0;36mppmCalc\u001b[0;34m(a, b, tol)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mppmCalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0;31m#   massError = abs(a-b)*1e6/a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmassError\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ma\u001b[0m  \u001b[0;31m#calculates ppm error of the a(theoretical) from b(observed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "df_split = np.array_split(expDF, 20)\n",
    "cnt=1\n",
    "for x in df_split:\n",
    "    final_result = search(x,libDF,n_ions, ms2_tol,ms1_tol, int_sd_dict,topRanks,method=\"normalized_dot_product\")\n",
    "    print (\"TOtal frames completed {}\".format(cnt))\n",
    "    cnt+=1\n",
    "    results_list.append(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-shoot",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-habitat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "danish-operations",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "19\n",
      "20\n",
      "21\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "24\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "30\n",
      "31\n",
      "32\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "36\n",
      "36\n",
      "36\n",
      "37\n",
      "38\n",
      "38\n",
      "38\n",
      "39\n",
      "39\n",
      "40\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "45\n",
      "46\n",
      "47\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "52\n",
      "52\n",
      "53\n",
      "53\n",
      "53\n",
      "54\n",
      "55\n",
      "55\n",
      "55\n",
      "56\n",
      "57\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "10.730446100234985\n"
     ]
    }
   ],
   "source": [
    "#5:20PM\n",
    "start_time=time.time()\n",
    "final_result = search(expDF,libDF,n_ions, ms2_tol,ms1_tol, int_sd_dict,topRanks,method=\"normalized_dot_product\")\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-dinner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adjusted-collect",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-46-db5cff2dfa94>\", line 17, in search\n",
      "    matched_lib_DF = scanPrecursorMatch(precMZ, charge, libDF, ms1_tol)\n",
      "  File \"/Users/spoudel1/Desktop/JUMPp_lib_program/JumplibrarySearchParallel_TwoScores/mainSearchFunctions.py\", line 250, in scanPrecursorMatch\n",
      "    libDF_matched = libDF.loc[(libDF.prec_MZ.astype(\"float\") >= min_prec_mzCheck) & (libDF.prec_MZ.astype(\"float\") <= max_prec_mzCheck) & (libDF.charge == charge)]\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 895, in __getitem__\n",
      "    return self._getitem_axis(maybe_callable, axis=axis)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 1104, in _getitem_axis\n",
      "    return self._getbool_axis(key, axis=axis)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/indexing.py\", line 914, in _getbool_axis\n",
      "    return self.obj._take_with_is_copy(inds, axis=axis)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py\", line 3600, in _take_with_is_copy\n",
      "    result = self.take(indices=indices, axis=axis)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/generic.py\", line 3587, in take\n",
      "    indices, axis=self._get_block_manager_axis(axis), verify=True\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1475, in take\n",
      "    new_axis=new_labels, indexer=indexer, axis=axis, allow_dups=True\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1319, in reindex_indexer\n",
      "    for blk in self.blocks\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\", line 1319, in <listcomp>\n",
      "    for blk in self.blocks\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\", line 1386, in take_nd\n",
      "    values, indexer, axis=axis, allow_fill=allow_fill, fill_value=fill_value\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/algorithms.py\", line 1759, in take_nd\n",
      "    func(arr, indexer, out, fill_value)\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 354, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\", line 127, in _new_Index\n",
      "    def _new_Index(cls, d):\n",
      "KeyboardInterrupt\n",
      "Process ForkPoolWorker-47:\n",
      "Process ForkPoolWorker-44:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "Process ForkPoolWorker-50:\n",
      "Process ForkPoolWorker-49:\n",
      "  File \"<ipython-input-46-db5cff2dfa94>\", line 21, in search\n",
      "    matched_lib_DF_top2 = select_TopN_Lib_ions(mz, intensity, matched_lib_DF, n_ions, ms2_tol, topRanks)\n",
      "Process ForkPoolWorker-51:\n",
      "  File \"<ipython-input-46-db5cff2dfa94>\", line 57, in search\n",
      "    tr_featSpec = trimFeatSpec(spectrumInputDict,tolInputDict,int_sd_dict,tolerance_type,lib_mz_int_dict,ms2_tol) #int_sd_dict = tolerance SD defined intensity from the file after mass calibration\n",
      "Process ForkPoolWorker-48:\n",
      "Process ForkPoolWorker-45:\n",
      "Process ForkPoolWorker-46:\n",
      "  File \"/Users/spoudel1/Desktop/JUMPp_lib_program/JumplibrarySearchParallel_TwoScores/mainSearchFunctions.py\", line 87, in trimFeatSpec\n",
      "    massshift = ppmCalc(float(mzLib), float(masses), tol=tol_max)\n",
      "  File \"<ipython-input-20-44b08c82d004>\", line 31, in select_TopN_Lib_ions\n",
      "    massshift = ppmCalc(float(ion), float(masses), ms2_tol)\n",
      "Process ForkPoolWorker-43:\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/spoudel1/Desktop/JUMPp_lib_program/JumplibrarySearchParallel_TwoScores/normalization_PSMSHandler.py\", line 21, in ppmCalc\n",
      "    massError = (b-a)*1e6/a  #calculates ppm error of the a(theoretical) from b(observed)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/pool.py\", line 110, in worker\n",
      "    task = get()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 352, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/queues.py\", line 351, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/spoudel1/miniconda3/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "#library searching results are kept as a dictionary final result\n",
    "# final_result = librarySearchMain(expDF,libDF,top_ions,ms2_tol,ms1_tol,top_ions_per_bin,binsize,tolerance_type,int_sd_dict, method, sim_mass)\n",
    "# final_result = librarySearchMain(expDF,libDF,top_ions,ms2_tol,ms1_tol,top_ions_per_bin,binsize,tolerance_type,int_sd_dict, method\n",
    "\n",
    "#use multiprocessing here\n",
    "#Define arguments that goes after the main dataframe that is going to be searched expDF\n",
    "\n",
    "args = (libDF,n_ions, ms2_tol,ms1_tol, int_sd_dict,topRanks,\"normalized_dot_product\")\n",
    "\n",
    "#initialize empty dictionary to update after multiple processing\n",
    "final_result = {}\n",
    "#calling the parrallel function. result variable will be the list of result of 4 processes\n",
    "#input is the input DF for searching and remaining arguments args\n",
    "result = parallelize_dataframe(search,expDF, args,  n_cores=n_cores)\n",
    "for x in result:\n",
    "    final_result.update(x.get()) #main work of the workers. The result is updated to the final result\n",
    "\n",
    "    \n",
    "print(time.time() - start_time,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_log (logFile,\"Total candidates psms (all Ranks) before filtering = {}\".format(len(final_result.keys())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consolidation of one psms to one scan for TMT data\n",
    "printDF2Rank1, printDF2 = postsearchProcessing(expDF, final_result, outputFolder,tmt,logFile, exp_ms2, L_ID_allProtDict) #sta_AA helps us to see if the data is TMT or not {'K': 304.2071453, 'C': 57.02146, 'n': 304.2071453} #for tmt K and n values are equal\n",
    "\n",
    "cmd2 = \"cp \"+params_file+\" \"+outputFolder\n",
    "os.system(cmd2)\n",
    "\n",
    "\n",
    "write_log (logFile,\"The JUMPp-lib search is complete for {}\".format(exp_ms2))\n",
    "write_log (logFile,\"Time taken for library search and filter --- %s seconds ---\" % (time.time() - start_time))\n",
    "write_log (logFile,\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-kingston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
